{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from statistics import mode\n",
    "from scipy.stats import norm\n",
    "from future.utils import iteritems\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement the EM-algorithm to find a Gaussian NBC for the digits dataset from SciKitLearn (you can of course also use the MNIST_Light set from Lab 5, but for initial tests the digits data set is more convenient, since it is smaller in various aspects). You may assume (conditional) independence between the attributes, i.e., the covariances can be assumed to be simply the variances over each attribute. Split the data set in 70% training and 30% test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciKitLearn digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = datasets.load_digits(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)\n",
    "# Normalize the pixelvalues from range(0,17) to range(0,1)\n",
    "X_train = X_train/16\n",
    "X_test = X_test/16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract max and min values of mean and variance which is used later to know in what range the initialized variance and mean in the EM algorithm should span between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean min: 0.224609375 mean max: 0.3955078125\n",
      "var min: 0.09405517578125 var max: 0.1777191162109375\n"
     ]
    }
   ],
   "source": [
    "m = np.zeros(64)\n",
    "var = np.zeros(64)\n",
    "for i in range(64):\n",
    "    m[i] = np.mean(X_train[i])\n",
    "    var[i] = np.var(X_train[i])\n",
    "print('mean min:',min(m),'mean max:',max(m))\n",
    "print('var min:',min(var),'var max:',max(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EM:\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        \n",
    "    def fit(self, X_train, eps): #, keep=True\n",
    "        \n",
    "        # Uniform distribution for mean, variance and priors\n",
    "        self.gaussian = {cl: {'mean':np.random.uniform(1,size=X_train[0].size), #len(X_train[0])\n",
    "                               'var':np.random.uniform(0.5,size=X_train[0].size)} for cl in range(self.num_classes)}\n",
    "        self.priors = {k:1/self.num_classes for k in range(self.num_classes)}\n",
    "        \n",
    "        for i in range(100): # while not diff > epsilon approximately 0.01\n",
    "                            # diff = abs(norm(mean_old)-norm(mean))\n",
    "                            # mean_old = mean\n",
    "            # E_step\n",
    "            r = np.zeros((len(X_train), self.num_classes))\n",
    "            \n",
    "            for index,x in enumerate(X_train):\n",
    "                num = np.prod([norm.pdf(x, self.gaussian[k]['mean'], np.sqrt(self.gaussian[k]['var']))\n",
    "                      for k in range(self.num_classes)], axis = 1)\n",
    "                num = [self.priors[k]*num[k] for k in range(self.num_classes)]\n",
    "                den = np.sum(num)\n",
    "                r[index,:] = num/den\n",
    "                \n",
    "            # M_step\n",
    "            N, c = r.shape  \n",
    "            self.priors = {c:np.sum(r[:,c])/N for c in range(self.num_classes)}\n",
    "            mean = np.zeros(len(X_train[0]))\n",
    "            for c in range(self.num_classes):\n",
    "                mean = np.sum([r[index,c]*xi for index, xi in enumerate(X_train)], axis=0)/np.sum(r[:,c])\n",
    "                self.gaussian[c]['mean'] = mean\n",
    "                self.gaussian[c]['var'] = np.sum([r[index,c]*np.diag(np.outer(xi, xi)) for index, xi in enumerate(X_train)], axis=0)/np.sum(r[:,c]) - np.diag(np.outer(mean, mean)) + eps\n",
    "\n",
    "       # return self.gaussian, self.priors\n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        # Builds the P matrix of size (number images, number of classes)\n",
    "        row, col = X_test.shape\n",
    "        G = len(self.gaussian)\n",
    "        P = np.zeros((row, G))\n",
    "        for c, g in iteritems(self.gaussian):\n",
    "            mean, var = g['mean'], g['var']\n",
    "            # We can choose the digit class using c = argmax_c(logP(x|c)+logP(c))\n",
    "            # mvn.logpdf() since we wants log of the probability density function\n",
    "            \n",
    "            P[:,c] = mvn.logpdf(X_test, mean=mean, cov=var, allow_singular=True) + np.log(self.priors[c])\n",
    "\n",
    "        # axis = 1 since we want argmax along the rows    \n",
    "        return np.argmax(P, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = EM(10)\n",
    "eps = 1e-2\n",
    "em.fit(X_train, eps)\n",
    "y_pred_em = em.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the result of the EM-algorithm (the found distribution parameters) to cluster the training data (essentially, using the resulting classifier to do a prediction over the training data). Produce a confusion matrix over the known labels for the training data and your EM-generated clusters. What do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Homogeneity: score between 0.0 and 1.0. 1.0 stands for perfectly homogeneous labeling*\n",
    "\n",
    "*Completeness: score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling*\n",
    "\n",
    "*V_measure: harmonic mean of the first two*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Homogenity, Completeness, V-measure)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.68083051421843, 0.6934526680732898, 0.6870836268303576)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('(Homogenity, Completeness, V-measure)')\n",
    "metrics.homogeneity_completeness_v_measure(y_train, y_pred_em, beta=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. If necessary, find a way to \"repair\" the cluster assignments so that you can do a prediction run over the test data, from which you can compare the results with your earlier implementation of the Gaussian NBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair(X_train, y_train, y_pred):\n",
    "    \"\"\"Repair by studying closest centroid.\"\"\"\n",
    "    \n",
    "    k_classes = list(set(y_train))\n",
    "    c_true = {}\n",
    "    c_pred = {}\n",
    "    for kcl in k_classes:\n",
    "        c_true[kcl] = np.mean([X for i, X in enumerate(X_train) if y_train[i] == kcl], axis=0)\n",
    "        c_pred[kcl] = np.mean([X for i, X in enumerate(X_train) if y_pred[i] == kcl], axis=0)\n",
    "\n",
    "    pred2true = {}\n",
    "    for kcl in k_classes:\n",
    "        pred2true[kcl] = np.argmin([np.linalg.norm(c_pred[kcl] - c_true_v) for c_true_v in c_true.values()])\n",
    "    \n",
    "    y_new = []\n",
    "    for y in y_pred:\n",
    "        y_new.append(pred2true[y])\n",
    "    return np.asarray(y_new)\n",
    "\n",
    "\n",
    "def repair_ind(X_train, y_train, y_pred):\n",
    "    \"\"\"Repair by studying true labels compared to predicted and the search for the max occurance \n",
    "    to assign each label to its corresponding prediction.\"\"\"\n",
    "    \n",
    "    k_classes = list(set(y_train))\n",
    "    pred2true = {}\n",
    "    for kcl in k_classes:\n",
    "        indices = [i for i, x in enumerate(X_train) if y_pred[i] == kcl]\n",
    "        unique, counts= np.unique(y_train[indices], return_counts=True)\n",
    "        pred2true[kcl] = unique[np.argmax(counts)]\n",
    "        \n",
    "    y_new = []\n",
    "    for y in y_pred:\n",
    "        y_new.append(pred2true[y])\n",
    "    return np.asarray(y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*repair_ind()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report SKLearn:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       125\n",
      "           1       0.47      0.46      0.47       132\n",
      "           2       0.84      0.87      0.85       130\n",
      "           3       0.44      0.74      0.55       129\n",
      "           4       0.48      0.43      0.45       121\n",
      "           5       0.96      0.73      0.83       116\n",
      "           6       0.98      0.97      0.98       128\n",
      "           7       0.69      0.98      0.81       124\n",
      "           8       0.70      0.80      0.74       131\n",
      "           9       0.00      0.00      0.00       121\n",
      "\n",
      "    accuracy                           0.70      1257\n",
      "   macro avg       0.65      0.70      0.67      1257\n",
      "weighted avg       0.66      0.70      0.67      1257\n",
      "\n",
      "\n",
      "Confusion matrix SKLearn:\n",
      "[[123   2   0   0   0   0   0   0   0   0]\n",
      " [  0  61  16   0  44   1   2   1   7   0]\n",
      " [  0   0 113   2   6   0   0   1   8   0]\n",
      " [  0   0   1  96   0   1   0   6  25   0]\n",
      " [  0  49   0   0  52   0   0  20   0   0]\n",
      " [  0   1   0  25   0  85   0   4   1   0]\n",
      " [  0   2   0   0   2   0 124   0   0   0]\n",
      " [  0   3   0   0   0   0   0 121   0   0]\n",
      " [  0  12   5   1   4   1   0   3 105   0]\n",
      " [  0   0   0  94   1   1   0  20   5   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred_repair_ind = repair_ind(X_train, y_train, y_pred_em)\n",
    "\n",
    "print(\"Classification report SKLearn:\\n%s\\n\"\n",
    "  % (metrics.classification_report(y_train, y_pred_repair_ind)))\n",
    "print(\"Confusion matrix SKLearn:\\n%s\" % metrics.confusion_matrix(y_train, y_pred_repair_ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homogenity, Completeness, V-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Homogenity, Completeness, V-measure)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6709536090053164, 0.7131908565248847, 0.6914277967533776)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('(Homogenity, Completeness, V-measure)')\n",
    "metrics.homogeneity_completeness_v_measure(y_train, y_pred_repair_ind, beta=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*repair()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report SKLearn:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       125\n",
      "           1       0.47      0.46      0.47       132\n",
      "           2       0.84      0.87      0.85       130\n",
      "           3       0.00      0.00      0.00       129\n",
      "           4       0.48      0.43      0.45       121\n",
      "           5       0.96      0.73      0.83       116\n",
      "           6       0.98      0.97      0.98       128\n",
      "           7       0.69      0.98      0.81       124\n",
      "           8       0.70      0.80      0.74       131\n",
      "           9       0.43      0.78      0.55       121\n",
      "\n",
      "    accuracy                           0.70      1257\n",
      "   macro avg       0.65      0.70      0.67      1257\n",
      "weighted avg       0.65      0.70      0.67      1257\n",
      "\n",
      "\n",
      "Confusion matrix SKLearn:\n",
      "[[123   2   0   0   0   0   0   0   0   0]\n",
      " [  0  61  16   0  44   1   2   1   7   0]\n",
      " [  0   0 113   0   6   0   0   1   8   2]\n",
      " [  0   0   1   0   0   1   0   6  25  96]\n",
      " [  0  49   0   0  52   0   0  20   0   0]\n",
      " [  0   1   0   0   0  85   0   4   1  25]\n",
      " [  0   2   0   0   2   0 124   0   0   0]\n",
      " [  0   3   0   0   0   0   0 121   0   0]\n",
      " [  0  12   5   0   4   1   0   3 105   1]\n",
      " [  0   0   0   0   1   1   0  20   5  94]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred_repair = repair(X_train, y_train, y_pred_em)\n",
    "\n",
    "print(\"Classification report SKLearn:\\n%s\\n\"\n",
    "  % (metrics.classification_report(y_train, y_pred_repair)))\n",
    "print(\"Confusion matrix SKLearn:\\n%s\" % metrics.confusion_matrix(y_train, y_pred_repair))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homogenity, Completeness, V-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Homogenity, Completeness, V-measure)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6709536090053164, 0.7131908565248846, 0.6914277967533775)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('(Homogenity, Completeness, V-measure)')\n",
    "metrics.homogeneity_completeness_v_measure(y_train, y_pred_repair, beta=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use now also the k-Means implementation from SciKitLearn and compare the results to yours (they should be similar at least in the sense that there are classes that are more clearly separated from the rest than others for both approaches). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=42).fit(X_train)\n",
    "km_pred = kmeans.predict(X_train)\n",
    "km_pred_repair = repair_ind(X_train, y_train, km_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report SKLearn:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       125\n",
      "           1       0.73      0.86      0.79       132\n",
      "           2       0.85      0.82      0.83       130\n",
      "           3       0.46      0.88      0.60       129\n",
      "           4       0.99      0.89      0.94       121\n",
      "           5       0.92      0.85      0.88       116\n",
      "           6       0.97      0.97      0.97       128\n",
      "           7       0.84      0.90      0.87       124\n",
      "           8       0.79      0.75      0.77       131\n",
      "           9       0.00      0.00      0.00       121\n",
      "\n",
      "    accuracy                           0.79      1257\n",
      "   macro avg       0.75      0.79      0.77      1257\n",
      "weighted avg       0.75      0.79      0.77      1257\n",
      "\n",
      "\n",
      "Confusion matrix SKLearn:\n",
      "[[124   0   0   0   1   0   0   0   0   0]\n",
      " [  0 114  14   0   0   1   3   0   0   0]\n",
      " [  1   4 106  11   0   0   0   2   6   0]\n",
      " [  0   0   1 114   0   2   0   6   6   0]\n",
      " [  0   4   0   0 108   0   0   6   3   0]\n",
      " [  0   0   0  17   0  99   0   0   0   0]\n",
      " [  0   3   0   0   0   0 124   0   1   0]\n",
      " [  0   3   0   0   0   0   0 112   9   0]\n",
      " [  0  13   3  10   0   2   1   4  98   0]\n",
      " [  0  15   0  97   0   4   0   4   1   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report SKLearn:\\n%s\\n\"\n",
    "  % (metrics.classification_report(y_train, km_pred_repair)))\n",
    "print(\"Confusion matrix SKLearn:\\n%s\" % metrics.confusion_matrix(y_train, km_pred_repair))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homogenity, Completeness, V-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Homogenity, Completeness, V-measure)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7291640278659127, 0.7769060897534751, 0.7522783528480621)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('(Homogenity, Completeness, V-measure)')\n",
    "metrics.homogeneity_completeness_v_measure(y_train, km_pred_repair, beta=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
